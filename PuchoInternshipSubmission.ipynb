{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PuchoInternshipSubmission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJXG5DzJCIylgkQBuF/LpL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasad-dash/COVID-Model/blob/main/PuchoInternshipSubmission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aReDhBxHRMh9"
      },
      "source": [
        "##Procuring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPHQPFFlz2ug"
      },
      "source": [
        "!wget https://zenodo.org/record/4498364/files/public_dataset.zip?download=1\n",
        "!unzip /content/public_dataset.zip?download=1\n",
        "!cp ./public_dataset/metadata_compiled.csv /content\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOsQiMnJRLYJ"
      },
      "source": [
        "##Importing Libraries\n",
        "\n",
        "\n",
        "*   librosa\n",
        "*   numpy\n",
        "*   pandas\n",
        "*   shutil\n",
        "*   os\n",
        "*   matplotlib.pyplot\n",
        "*   sklearn\n",
        "*   scipy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYBy-3_z_I9I"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa as lb\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXqTh4AWSHG3"
      },
      "source": [
        "##Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP3NdtWSAFnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a28efd-c805-4178-fe2c-35d1427e661a"
      },
      "source": [
        "#The metadata_compiled file was moved to content directory for ease of working\n",
        "!cp /content/public_dataset/metadata_compiled.csv\n",
        "meta_dataset=pd.read_csv(\"/content/metadata_compiled.csv\")\n",
        "SIZE=len(meta_dataset)\n",
        "for column in meta_dataset.columns:\n",
        "  print(f'{column}:{meta_dataset[column].isna().sum()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: missing destination file operand after '/content/public_dataset/metadata_compiled.csv'\n",
            "Try 'cp --help' for more information.\n",
            "uuid:0\n",
            "datetime:0\n",
            "cough_detected:0\n",
            "SNR:0\n",
            "latitude:11466\n",
            "longitude:11466\n",
            "age:12332\n",
            "gender:11326\n",
            "respiratory_condition:11326\n",
            "fever_muscle_pain:11326\n",
            "status:11326\n",
            "quality_1:26730\n",
            "cough_type_1:26748\n",
            "dyspnea_1:26730\n",
            "wheezing_1:26730\n",
            "stridor_1:26730\n",
            "choking_1:26730\n",
            "congestion_1:26730\n",
            "nothing_1:26730\n",
            "diagnosis_1:26748\n",
            "severity_1:26748\n",
            "quality_2:26730\n",
            "cough_type_2:26749\n",
            "dyspnea_2:26730\n",
            "wheezing_2:26730\n",
            "stridor_2:26730\n",
            "choking_2:26730\n",
            "congestion_2:26730\n",
            "nothing_2:26730\n",
            "diagnosis_2:26748\n",
            "severity_2:26748\n",
            "quality_3:26730\n",
            "cough_type_3:26755\n",
            "dyspnea_3:26730\n",
            "wheezing_3:26730\n",
            "stridor_3:26730\n",
            "choking_3:26730\n",
            "congestion_3:26730\n",
            "nothing_3:26730\n",
            "diagnosis_3:26758\n",
            "severity_3:26755\n",
            "quality_4:26730\n",
            "cough_type_4:26749\n",
            "dyspnea_4:26730\n",
            "wheezing_4:26730\n",
            "stridor_4:26730\n",
            "choking_4:26730\n",
            "congestion_4:26730\n",
            "nothing_4:26730\n",
            "diagnosis_4:26761\n",
            "severity_4:26751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ErH-V-IATzJ"
      },
      "source": [
        "SIZE=len(meta_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "aswgmVafBrV4",
        "outputId": "2bbf33b0-55b2-44a9-b192-6d0dc31e178e"
      },
      "source": [
        "meta_dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>datetime</th>\n",
              "      <th>cough_detected</th>\n",
              "      <th>SNR</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>respiratory_condition</th>\n",
              "      <th>fever_muscle_pain</th>\n",
              "      <th>status</th>\n",
              "      <th>quality_1</th>\n",
              "      <th>cough_type_1</th>\n",
              "      <th>dyspnea_1</th>\n",
              "      <th>wheezing_1</th>\n",
              "      <th>stridor_1</th>\n",
              "      <th>choking_1</th>\n",
              "      <th>congestion_1</th>\n",
              "      <th>nothing_1</th>\n",
              "      <th>diagnosis_1</th>\n",
              "      <th>severity_1</th>\n",
              "      <th>quality_2</th>\n",
              "      <th>cough_type_2</th>\n",
              "      <th>dyspnea_2</th>\n",
              "      <th>wheezing_2</th>\n",
              "      <th>stridor_2</th>\n",
              "      <th>choking_2</th>\n",
              "      <th>congestion_2</th>\n",
              "      <th>nothing_2</th>\n",
              "      <th>diagnosis_2</th>\n",
              "      <th>severity_2</th>\n",
              "      <th>quality_3</th>\n",
              "      <th>cough_type_3</th>\n",
              "      <th>dyspnea_3</th>\n",
              "      <th>wheezing_3</th>\n",
              "      <th>stridor_3</th>\n",
              "      <th>choking_3</th>\n",
              "      <th>congestion_3</th>\n",
              "      <th>nothing_3</th>\n",
              "      <th>diagnosis_3</th>\n",
              "      <th>severity_3</th>\n",
              "      <th>quality_4</th>\n",
              "      <th>cough_type_4</th>\n",
              "      <th>dyspnea_4</th>\n",
              "      <th>wheezing_4</th>\n",
              "      <th>stridor_4</th>\n",
              "      <th>choking_4</th>\n",
              "      <th>congestion_4</th>\n",
              "      <th>nothing_4</th>\n",
              "      <th>diagnosis_4</th>\n",
              "      <th>severity_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00014dcc-0f06-4c27-8c7b-737b18a2cf4c</td>\n",
              "      <td>2020-11-25T18:58:50.488301+00:00</td>\n",
              "      <td>0.0155</td>\n",
              "      <td>7.326171</td>\n",
              "      <td>48.9</td>\n",
              "      <td>2.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00039425-7f3a-42aa-ac13-834aaa2b6b92</td>\n",
              "      <td>2020-04-13T21:30:59.801831+00:00</td>\n",
              "      <td>0.9609</td>\n",
              "      <td>16.151433</td>\n",
              "      <td>31.3</td>\n",
              "      <td>34.8</td>\n",
              "      <td>15.0</td>\n",
              "      <td>male</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0007c6f1-5441-40e6-9aaf-a761d8f2da3b</td>\n",
              "      <td>2020-10-18T15:38:38.205870+00:00</td>\n",
              "      <td>0.1643</td>\n",
              "      <td>16.217201</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>46.0</td>\n",
              "      <td>female</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0009eb28-d8be-4dc1-92bb-907e53bc5c7a</td>\n",
              "      <td>2020-04-12T04:02:18.159383+00:00</td>\n",
              "      <td>0.9301</td>\n",
              "      <td>20.146058</td>\n",
              "      <td>40.0</td>\n",
              "      <td>-75.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>male</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0012c608-33d0-4ef7-bde3-75a0b1a0024e</td>\n",
              "      <td>2020-04-15T01:03:59.029326+00:00</td>\n",
              "      <td>0.0482</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-16.5</td>\n",
              "      <td>-71.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>001328dc-ea5d-4847-9ccf-c5aa2a3f2d0f</td>\n",
              "      <td>2020-04-13T22:23:06.997578+00:00</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>13.146502</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>male</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>001c85a8-cc4d-4921-9297-848be52d4715</td>\n",
              "      <td>2020-04-17T15:24:35.822355+00:00</td>\n",
              "      <td>0.0735</td>\n",
              "      <td>23.014715</td>\n",
              "      <td>40.6</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>001d8e33-a4af-4edb-98ba-b03f891d9a6c</td>\n",
              "      <td>2020-05-13T01:27:42.552773+00:00</td>\n",
              "      <td>0.0306</td>\n",
              "      <td>12.713480</td>\n",
              "      <td>13.8</td>\n",
              "      <td>-89.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>COVID-19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>001e2f19-d81c-4029-b33c-d2db56b23a4a</td>\n",
              "      <td>2020-10-18T15:11:02.106636+00:00</td>\n",
              "      <td>0.7811</td>\n",
              "      <td>12.566406</td>\n",
              "      <td>45.7</td>\n",
              "      <td>4.9</td>\n",
              "      <td>20.0</td>\n",
              "      <td>male</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00273cdf-ed90-4105-84ec-0c88d52f1dc0</td>\n",
              "      <td>2020-05-15T08:50:59.481638+00:00</td>\n",
              "      <td>0.0307</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.6</td>\n",
              "      <td>-6.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   uuid  ... severity_4\n",
              "0  00014dcc-0f06-4c27-8c7b-737b18a2cf4c  ...        NaN\n",
              "1  00039425-7f3a-42aa-ac13-834aaa2b6b92  ...        NaN\n",
              "2  0007c6f1-5441-40e6-9aaf-a761d8f2da3b  ...        NaN\n",
              "3  0009eb28-d8be-4dc1-92bb-907e53bc5c7a  ...        NaN\n",
              "4  0012c608-33d0-4ef7-bde3-75a0b1a0024e  ...        NaN\n",
              "5  001328dc-ea5d-4847-9ccf-c5aa2a3f2d0f  ...        NaN\n",
              "6  001c85a8-cc4d-4921-9297-848be52d4715  ...        NaN\n",
              "7  001d8e33-a4af-4edb-98ba-b03f891d9a6c  ...        NaN\n",
              "8  001e2f19-d81c-4029-b33c-d2db56b23a4a  ...        NaN\n",
              "9  00273cdf-ed90-4105-84ec-0c88d52f1dc0  ...        NaN\n",
              "\n",
              "[10 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Vivk8TUv6K"
      },
      "source": [
        "###Using Cough sound to detect covid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfTK8BFOTzh3"
      },
      "source": [
        "covDataset=meta_dataset.iloc[meta_dataset.status.dropna().index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "8xc8Q6HEVBK5",
        "outputId": "52176c64-d5f6-400b-ed2c-f8aa744ffbf0"
      },
      "source": [
        "covDataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>datetime</th>\n",
              "      <th>cough_detected</th>\n",
              "      <th>SNR</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>respiratory_condition</th>\n",
              "      <th>fever_muscle_pain</th>\n",
              "      <th>status</th>\n",
              "      <th>quality_1</th>\n",
              "      <th>cough_type_1</th>\n",
              "      <th>dyspnea_1</th>\n",
              "      <th>wheezing_1</th>\n",
              "      <th>stridor_1</th>\n",
              "      <th>choking_1</th>\n",
              "      <th>congestion_1</th>\n",
              "      <th>nothing_1</th>\n",
              "      <th>diagnosis_1</th>\n",
              "      <th>severity_1</th>\n",
              "      <th>quality_2</th>\n",
              "      <th>cough_type_2</th>\n",
              "      <th>dyspnea_2</th>\n",
              "      <th>wheezing_2</th>\n",
              "      <th>stridor_2</th>\n",
              "      <th>choking_2</th>\n",
              "      <th>congestion_2</th>\n",
              "      <th>nothing_2</th>\n",
              "      <th>diagnosis_2</th>\n",
              "      <th>severity_2</th>\n",
              "      <th>quality_3</th>\n",
              "      <th>cough_type_3</th>\n",
              "      <th>dyspnea_3</th>\n",
              "      <th>wheezing_3</th>\n",
              "      <th>stridor_3</th>\n",
              "      <th>choking_3</th>\n",
              "      <th>congestion_3</th>\n",
              "      <th>nothing_3</th>\n",
              "      <th>diagnosis_3</th>\n",
              "      <th>severity_3</th>\n",
              "      <th>quality_4</th>\n",
              "      <th>cough_type_4</th>\n",
              "      <th>dyspnea_4</th>\n",
              "      <th>wheezing_4</th>\n",
              "      <th>stridor_4</th>\n",
              "      <th>choking_4</th>\n",
              "      <th>congestion_4</th>\n",
              "      <th>nothing_4</th>\n",
              "      <th>diagnosis_4</th>\n",
              "      <th>severity_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00039425-7f3a-42aa-ac13-834aaa2b6b92</td>\n",
              "      <td>2020-04-13T21:30:59.801831+00:00</td>\n",
              "      <td>0.9609</td>\n",
              "      <td>16.151433</td>\n",
              "      <td>31.3</td>\n",
              "      <td>34.8</td>\n",
              "      <td>15.0</td>\n",
              "      <td>male</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0007c6f1-5441-40e6-9aaf-a761d8f2da3b</td>\n",
              "      <td>2020-10-18T15:38:38.205870+00:00</td>\n",
              "      <td>0.1643</td>\n",
              "      <td>16.217201</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>46.0</td>\n",
              "      <td>female</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0009eb28-d8be-4dc1-92bb-907e53bc5c7a</td>\n",
              "      <td>2020-04-12T04:02:18.159383+00:00</td>\n",
              "      <td>0.9301</td>\n",
              "      <td>20.146058</td>\n",
              "      <td>40.0</td>\n",
              "      <td>-75.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>male</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>001328dc-ea5d-4847-9ccf-c5aa2a3f2d0f</td>\n",
              "      <td>2020-04-13T22:23:06.997578+00:00</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>13.146502</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>male</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>001d8e33-a4af-4edb-98ba-b03f891d9a6c</td>\n",
              "      <td>2020-05-13T01:27:42.552773+00:00</td>\n",
              "      <td>0.0306</td>\n",
              "      <td>12.713480</td>\n",
              "      <td>13.8</td>\n",
              "      <td>-89.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>COVID-19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   uuid  ... severity_4\n",
              "1  00039425-7f3a-42aa-ac13-834aaa2b6b92  ...        NaN\n",
              "2  0007c6f1-5441-40e6-9aaf-a761d8f2da3b  ...        NaN\n",
              "3  0009eb28-d8be-4dc1-92bb-907e53bc5c7a  ...        NaN\n",
              "5  001328dc-ea5d-4847-9ccf-c5aa2a3f2d0f  ...        NaN\n",
              "7  001d8e33-a4af-4edb-98ba-b03f891d9a6c  ...        NaN\n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSmb8WOSVDZ8",
        "outputId": "b3ee4fc7-3cef-4707-92b9-b45b73f74e45"
      },
      "source": [
        "covDataset.status.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "healthy        12479\n",
              "symptomatic     2590\n",
              "COVID-19        1155\n",
              "Name: status, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DORhUqNVdM1",
        "outputId": "0352ef61-a455-4d77-d0e8-32ec2f556e6f"
      },
      "source": [
        "i=1\n",
        "for col in covDataset.columns:\n",
        "  print(f'{i}.{col}: {covDataset[col].isna().sum()}')\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.uuid: 0\n",
            "2.datetime: 0\n",
            "3.cough_detected: 0\n",
            "4.SNR: 0\n",
            "5.latitude: 6487\n",
            "6.longitude: 6487\n",
            "7.age: 1006\n",
            "8.gender: 0\n",
            "9.respiratory_condition: 0\n",
            "10.fever_muscle_pain: 0\n",
            "11.status: 0\n",
            "12.quality_1: 15527\n",
            "13.cough_type_1: 15535\n",
            "14.dyspnea_1: 15527\n",
            "15.wheezing_1: 15527\n",
            "16.stridor_1: 15527\n",
            "17.choking_1: 15527\n",
            "18.congestion_1: 15527\n",
            "19.nothing_1: 15527\n",
            "20.diagnosis_1: 15535\n",
            "21.severity_1: 15535\n",
            "22.quality_2: 15532\n",
            "23.cough_type_2: 15543\n",
            "24.dyspnea_2: 15532\n",
            "25.wheezing_2: 15532\n",
            "26.stridor_2: 15532\n",
            "27.choking_2: 15532\n",
            "28.congestion_2: 15532\n",
            "29.nothing_2: 15532\n",
            "30.diagnosis_2: 15542\n",
            "31.severity_2: 15542\n",
            "32.quality_3: 15536\n",
            "33.cough_type_3: 15550\n",
            "34.dyspnea_3: 15536\n",
            "35.wheezing_3: 15536\n",
            "36.stridor_3: 15536\n",
            "37.choking_3: 15536\n",
            "38.congestion_3: 15536\n",
            "39.nothing_3: 15536\n",
            "40.diagnosis_3: 15553\n",
            "41.severity_3: 15550\n",
            "42.quality_4: 15423\n",
            "43.cough_type_4: 15442\n",
            "44.dyspnea_4: 15423\n",
            "45.wheezing_4: 15423\n",
            "46.stridor_4: 15423\n",
            "47.choking_4: 15423\n",
            "48.congestion_4: 15423\n",
            "49.nothing_4: 15423\n",
            "50.diagnosis_4: 15454\n",
            "51.severity_4: 15444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaMxKDwS-mHv"
      },
      "source": [
        "###Preparing the training and test datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLD5-Gc8iNIX"
      },
      "source": [
        "files=[file for file in os.listdir(\"./public_dataset\")]\n",
        "covDataset=covDataset.iloc[:,[0,10]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2a3CuuyJQvbi",
        "outputId": "ddc0d61d-4980-44f7-98de-61cc3acfd78d"
      },
      "source": [
        "covDataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00039425-7f3a-42aa-ac13-834aaa2b6b92</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0007c6f1-5441-40e6-9aaf-a761d8f2da3b</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0009eb28-d8be-4dc1-92bb-907e53bc5c7a</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>001328dc-ea5d-4847-9ccf-c5aa2a3f2d0f</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>001d8e33-a4af-4edb-98ba-b03f891d9a6c</td>\n",
              "      <td>COVID-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   uuid    status\n",
              "1  00039425-7f3a-42aa-ac13-834aaa2b6b92   healthy\n",
              "2  0007c6f1-5441-40e6-9aaf-a761d8f2da3b   healthy\n",
              "3  0009eb28-d8be-4dc1-92bb-907e53bc5c7a   healthy\n",
              "5  001328dc-ea5d-4847-9ccf-c5aa2a3f2d0f   healthy\n",
              "7  001d8e33-a4af-4edb-98ba-b03f891d9a6c  COVID-19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX7LRIRElQzK"
      },
      "source": [
        "###Methods used:\n",
        "\n",
        "The paper used in the suggested dataset involved thr use of MFCC along with other spectral feautures.I have extracted the MFCCs of the given samples after segmenting them into blobs of 8 seconds. I have built a simple deep-learning neural-net with four layers each with a relu activation function (the given code is written in sequential model but can also be presented in the functional model). There are total of 170343 parameters. Using only given data I am able to achive 75% validation accuracy is classifying the data as healthy ,symptomatic ,COVID-19 . I have also used k-fold cross vaidation while training. \n",
        "\n",
        "### Further possible impovements:\n",
        "\n",
        "The used data has not been cleaned completely ie some samples which dont have any sound have been marked with one of the categories. Also the paper which puts together data which references another paper whcich uses a more complicared neural net with convolutions and residual layers to train the dataset along with more spectral feautures and other sound data. These improvements have not been implemented but can possibly increase the accuracy even more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoLtHizIdHnk"
      },
      "source": [
        "X=[]\n",
        "y=[]\n",
        "segment_size=8\n",
        "for i in range(int(len(covDataset)*2/3)):\n",
        "  print(i)\n",
        "  if (covDataset.iloc[i,0]+'.webm') in files:\n",
        "    arr,sr=lb.load(f'./public_dataset/{covDataset.iloc[i,0]+\".webm\"}',sr=48000)\n",
        "  if (covDataset.iloc[i,0]+'.ogg') in files:\n",
        "    arr,sr=lb.load(f'./public_dataset/{covDataset.iloc[i,0]+\".ogg\"}',sr=48000)\n",
        "  duration=lb.get_duration(arr,sr=48000)\n",
        "  itime=0\n",
        "  ftime=0\n",
        "  for j in range(int(duration/segment_size)):\n",
        "    itime=j*segment_size\n",
        "    ftime=itime+segment_size\n",
        "    feautures=lb.feature.mfcc(y=arr[itime:ftime], sr=sr, n_mfcc=10)\n",
        "    X.append(feautures)\n",
        "    y.append(covDataset.iloc[i,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkHh0WTcde-4"
      },
      "source": [
        "X=np.array(X)\n",
        "X=X.reshape(X.shape[0],X.shape[1])\n",
        "Le=preprocessing.LabelEncoder()\n",
        "y_t=Le.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQrJh_2CY8Km"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_t, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0e7wSWAbHaO"
      },
      "source": [
        "model=tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoOa8ezvbOd8"
      },
      "source": [
        "model.add(tf.keras.layers.InputLayer(10,))\n",
        "model.add(tf.keras.layers.Dense(512,))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "model.add(tf.keras.layers.Dense(128))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "model.add(tf.keras.layers.Dense(3))\n",
        "model.add(tf.keras.layers.Softmax())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-upFZp2fxdg"
      },
      "source": [
        "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5ko2hBoj2TS",
        "outputId": "d1ef6c48-1b28-449a-c025-0b7da9364cd2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_64 (Dense)             (None, 512)               5632      \n",
            "_________________________________________________________________\n",
            "re_lu_48 (ReLU)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "re_lu_49 (ReLU)              (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "re_lu_50 (ReLU)              (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 3)                 387       \n",
            "_________________________________________________________________\n",
            "softmax_16 (Softmax)         (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 170,243\n",
            "Trainable params: 170,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWaXR0gjf1Zk",
        "outputId": "42b06646-9c00-4c0a-cd87-90627d601039"
      },
      "source": [
        "model.fit(x=X_train,y=y_train,batch_size=32,epochs=100,validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 8.3078 - accuracy: 0.6233 - val_loss: 4.8313 - val_accuracy: 0.7561\n",
            "Epoch 2/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 1.5074 - accuracy: 0.6789 - val_loss: 0.8397 - val_accuracy: 0.7561\n",
            "Epoch 3/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.9203 - accuracy: 0.7208 - val_loss: 0.7667 - val_accuracy: 0.7561\n",
            "Epoch 4/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.9998 - accuracy: 0.7159 - val_loss: 0.7144 - val_accuracy: 0.7561\n",
            "Epoch 5/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.8381 - accuracy: 0.7276 - val_loss: 0.7465 - val_accuracy: 0.7561\n",
            "Epoch 6/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.8454 - accuracy: 0.7349 - val_loss: 0.7294 - val_accuracy: 0.7561\n",
            "Epoch 7/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7445 - accuracy: 0.7631 - val_loss: 0.7430 - val_accuracy: 0.7561\n",
            "Epoch 8/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7487 - accuracy: 0.7666 - val_loss: 0.8218 - val_accuracy: 0.7561\n",
            "Epoch 9/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7514 - accuracy: 0.7605 - val_loss: 0.7222 - val_accuracy: 0.7561\n",
            "Epoch 10/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7064 - accuracy: 0.7666 - val_loss: 0.7182 - val_accuracy: 0.7561\n",
            "Epoch 11/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7184 - accuracy: 0.7666 - val_loss: 0.7139 - val_accuracy: 0.7561\n",
            "Epoch 12/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7136 - accuracy: 0.7666 - val_loss: 0.7312 - val_accuracy: 0.7561\n",
            "Epoch 13/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7102 - accuracy: 0.7666 - val_loss: 0.7366 - val_accuracy: 0.7561\n",
            "Epoch 14/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7191 - accuracy: 0.7666 - val_loss: 0.7145 - val_accuracy: 0.7561\n",
            "Epoch 15/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7296 - accuracy: 0.7666 - val_loss: 0.7431 - val_accuracy: 0.7561\n",
            "Epoch 16/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7075 - accuracy: 0.7666 - val_loss: 0.7116 - val_accuracy: 0.7561\n",
            "Epoch 17/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6975 - accuracy: 0.7666 - val_loss: 0.7140 - val_accuracy: 0.7561\n",
            "Epoch 18/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7094 - accuracy: 0.7666 - val_loss: 0.7124 - val_accuracy: 0.7561\n",
            "Epoch 19/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7076 - accuracy: 0.7666 - val_loss: 0.7574 - val_accuracy: 0.7561\n",
            "Epoch 20/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7010 - accuracy: 0.7666 - val_loss: 0.7183 - val_accuracy: 0.7561\n",
            "Epoch 21/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7206 - accuracy: 0.7666 - val_loss: 0.7125 - val_accuracy: 0.7561\n",
            "Epoch 22/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7053 - accuracy: 0.7666 - val_loss: 0.7228 - val_accuracy: 0.7561\n",
            "Epoch 23/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6997 - accuracy: 0.7666 - val_loss: 0.7170 - val_accuracy: 0.7561\n",
            "Epoch 24/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7072 - accuracy: 0.7666 - val_loss: 0.7177 - val_accuracy: 0.7561\n",
            "Epoch 25/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6980 - accuracy: 0.7666 - val_loss: 0.7340 - val_accuracy: 0.7561\n",
            "Epoch 26/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7061 - accuracy: 0.7666 - val_loss: 0.7128 - val_accuracy: 0.7561\n",
            "Epoch 27/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6970 - accuracy: 0.7666 - val_loss: 0.7315 - val_accuracy: 0.7561\n",
            "Epoch 28/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6970 - accuracy: 0.7666 - val_loss: 0.7550 - val_accuracy: 0.7561\n",
            "Epoch 29/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6975 - accuracy: 0.7666 - val_loss: 0.7153 - val_accuracy: 0.7561\n",
            "Epoch 30/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.7010 - accuracy: 0.7666 - val_loss: 0.7184 - val_accuracy: 0.7561\n",
            "Epoch 31/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6936 - accuracy: 0.7666 - val_loss: 0.7122 - val_accuracy: 0.7561\n",
            "Epoch 32/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6955 - accuracy: 0.7666 - val_loss: 0.7174 - val_accuracy: 0.7561\n",
            "Epoch 33/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6980 - accuracy: 0.7666 - val_loss: 0.7102 - val_accuracy: 0.7561\n",
            "Epoch 34/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6946 - accuracy: 0.7666 - val_loss: 0.7116 - val_accuracy: 0.7561\n",
            "Epoch 35/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.7666 - val_loss: 0.7115 - val_accuracy: 0.7561\n",
            "Epoch 36/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6968 - accuracy: 0.7666 - val_loss: 0.7114 - val_accuracy: 0.7561\n",
            "Epoch 37/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6916 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 38/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 39/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7099 - val_accuracy: 0.7561\n",
            "Epoch 40/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7099 - val_accuracy: 0.7561\n",
            "Epoch 41/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 42/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7103 - val_accuracy: 0.7561\n",
            "Epoch 43/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6903 - accuracy: 0.7666 - val_loss: 0.7107 - val_accuracy: 0.7561\n",
            "Epoch 44/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6902 - accuracy: 0.7666 - val_loss: 0.7099 - val_accuracy: 0.7561\n",
            "Epoch 45/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 46/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7102 - val_accuracy: 0.7561\n",
            "Epoch 47/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 48/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7107 - val_accuracy: 0.7561\n",
            "Epoch 49/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 50/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 51/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 52/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6906 - accuracy: 0.7666 - val_loss: 0.7102 - val_accuracy: 0.7561\n",
            "Epoch 53/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7102 - val_accuracy: 0.7561\n",
            "Epoch 54/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6902 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 55/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7106 - val_accuracy: 0.7561\n",
            "Epoch 56/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7103 - val_accuracy: 0.7561\n",
            "Epoch 57/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6903 - accuracy: 0.7666 - val_loss: 0.7105 - val_accuracy: 0.7561\n",
            "Epoch 58/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7108 - val_accuracy: 0.7561\n",
            "Epoch 59/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7102 - val_accuracy: 0.7561\n",
            "Epoch 60/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 61/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6902 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 62/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6906 - accuracy: 0.7666 - val_loss: 0.7102 - val_accuracy: 0.7561\n",
            "Epoch 63/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 64/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7102 - val_accuracy: 0.7561\n",
            "Epoch 65/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 66/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7105 - val_accuracy: 0.7561\n",
            "Epoch 67/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6909 - accuracy: 0.7666 - val_loss: 0.7115 - val_accuracy: 0.7561\n",
            "Epoch 68/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6906 - accuracy: 0.7666 - val_loss: 0.7110 - val_accuracy: 0.7561\n",
            "Epoch 69/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 70/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7112 - val_accuracy: 0.7561\n",
            "Epoch 71/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 72/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7109 - val_accuracy: 0.7561\n",
            "Epoch 73/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7103 - val_accuracy: 0.7561\n",
            "Epoch 74/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 75/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6908 - accuracy: 0.7666 - val_loss: 0.7105 - val_accuracy: 0.7561\n",
            "Epoch 76/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7112 - val_accuracy: 0.7561\n",
            "Epoch 77/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6908 - accuracy: 0.7666 - val_loss: 0.7112 - val_accuracy: 0.7561\n",
            "Epoch 78/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6906 - accuracy: 0.7666 - val_loss: 0.7103 - val_accuracy: 0.7561\n",
            "Epoch 79/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7108 - val_accuracy: 0.7561\n",
            "Epoch 80/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6908 - accuracy: 0.7666 - val_loss: 0.7103 - val_accuracy: 0.7561\n",
            "Epoch 81/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 82/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 83/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 84/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6908 - accuracy: 0.7666 - val_loss: 0.7111 - val_accuracy: 0.7561\n",
            "Epoch 85/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6909 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 86/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6909 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 87/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7107 - val_accuracy: 0.7561\n",
            "Epoch 88/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 89/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7117 - val_accuracy: 0.7561\n",
            "Epoch 90/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6908 - accuracy: 0.7666 - val_loss: 0.7104 - val_accuracy: 0.7561\n",
            "Epoch 91/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 92/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6908 - accuracy: 0.7666 - val_loss: 0.7102 - val_accuracy: 0.7561\n",
            "Epoch 93/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6907 - accuracy: 0.7666 - val_loss: 0.7099 - val_accuracy: 0.7561\n",
            "Epoch 94/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7666 - val_loss: 0.7107 - val_accuracy: 0.7561\n",
            "Epoch 95/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6906 - accuracy: 0.7666 - val_loss: 0.7099 - val_accuracy: 0.7561\n",
            "Epoch 96/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6905 - accuracy: 0.7666 - val_loss: 0.7121 - val_accuracy: 0.7561\n",
            "Epoch 97/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6909 - accuracy: 0.7666 - val_loss: 0.7100 - val_accuracy: 0.7561\n",
            "Epoch 98/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6904 - accuracy: 0.7666 - val_loss: 0.7131 - val_accuracy: 0.7561\n",
            "Epoch 99/100\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 0.6909 - accuracy: 0.7666 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 100/100\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 0.6906 - accuracy: 0.7666 - val_loss: 0.7099 - val_accuracy: 0.7561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8b2a7cb450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gYKPgzDjxBm"
      },
      "source": [
        "###K-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhPEorNSspV_",
        "outputId": "8f3ec4fe-8338-4acb-cbae-b14463abe0d9"
      },
      "source": [
        "len(y_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APSucgFNhsgZ",
        "outputId": "968c60aa-b10d-406e-92ab-e9767d89f95d"
      },
      "source": [
        "Kmodel=tf.keras.models.Sequential()\n",
        "Kmodel.add(tf.keras.layers.InputLayer(10,))\n",
        "Kmodel.add(tf.keras.layers.Dense(512,))\n",
        "Kmodel.add(tf.keras.layers.ReLU())\n",
        "Kmodel.add(tf.keras.layers.Dense(256))\n",
        "Kmodel.add(tf.keras.layers.ReLU())\n",
        "Kmodel.add(tf.keras.layers.Dense(128))\n",
        "Kmodel.add(tf.keras.layers.ReLU())\n",
        "Kmodel.add(tf.keras.layers.Dense(3))\n",
        "Kmodel.add(tf.keras.layers.Softmax())\n",
        "Kmodel.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "fold_no=0\n",
        "for train, test in kfold.split(X, y_t):\n",
        "  Kmodel.fit(X[train], y_t[train],batch_size=32,epochs=100,validation_data=(X[test],y_t[test]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 4.8078 - accuracy: 0.6114 - val_loss: 0.8342 - val_accuracy: 0.7743\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 1.2056 - accuracy: 0.6728 - val_loss: 0.7481 - val_accuracy: 0.7743\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.9687 - accuracy: 0.7123 - val_loss: 1.4647 - val_accuracy: 0.1532\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.9300 - accuracy: 0.7036 - val_loss: 0.8134 - val_accuracy: 0.7743\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7935 - accuracy: 0.7414 - val_loss: 0.7082 - val_accuracy: 0.7743\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7640 - accuracy: 0.7549 - val_loss: 0.7733 - val_accuracy: 0.7743\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 4ms/step - loss: 0.7403 - accuracy: 0.7621 - val_loss: 0.6918 - val_accuracy: 0.7743\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7246 - accuracy: 0.7619 - val_loss: 0.6810 - val_accuracy: 0.7743\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7165 - accuracy: 0.7619 - val_loss: 0.7317 - val_accuracy: 0.7743\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 4ms/step - loss: 0.7138 - accuracy: 0.7619 - val_loss: 0.6790 - val_accuracy: 0.7743\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7064 - accuracy: 0.7619 - val_loss: 0.6863 - val_accuracy: 0.7743\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7110 - accuracy: 0.7619 - val_loss: 0.6810 - val_accuracy: 0.7743\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7083 - accuracy: 0.7621 - val_loss: 0.6874 - val_accuracy: 0.7743\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7092 - accuracy: 0.7621 - val_loss: 0.6800 - val_accuracy: 0.7743\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7069 - accuracy: 0.7621 - val_loss: 0.6813 - val_accuracy: 0.7743\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7098 - accuracy: 0.7619 - val_loss: 0.6796 - val_accuracy: 0.7743\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7038 - accuracy: 0.7621 - val_loss: 0.6767 - val_accuracy: 0.7743\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7149 - accuracy: 0.7621 - val_loss: 0.6781 - val_accuracy: 0.7743\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7090 - accuracy: 0.7621 - val_loss: 0.6865 - val_accuracy: 0.7743\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7101 - accuracy: 0.7621 - val_loss: 0.6775 - val_accuracy: 0.7743\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7057 - accuracy: 0.7621 - val_loss: 0.6766 - val_accuracy: 0.7743\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7068 - accuracy: 0.7621 - val_loss: 0.6812 - val_accuracy: 0.7743\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7055 - accuracy: 0.7621 - val_loss: 0.6759 - val_accuracy: 0.7743\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7112 - accuracy: 0.7621 - val_loss: 0.6759 - val_accuracy: 0.7743\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7042 - accuracy: 0.7621 - val_loss: 0.6787 - val_accuracy: 0.7743\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7029 - accuracy: 0.7621 - val_loss: 0.6844 - val_accuracy: 0.7743\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7043 - accuracy: 0.7621 - val_loss: 0.6778 - val_accuracy: 0.7743\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 4ms/step - loss: 0.7036 - accuracy: 0.7621 - val_loss: 0.6861 - val_accuracy: 0.7743\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 4ms/step - loss: 0.8020 - accuracy: 0.7441 - val_loss: 0.7885 - val_accuracy: 0.7743\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7460 - accuracy: 0.7552 - val_loss: 0.6761 - val_accuracy: 0.7743\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7000 - accuracy: 0.7621 - val_loss: 0.6786 - val_accuracy: 0.7743\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6997 - accuracy: 0.7621 - val_loss: 0.6767 - val_accuracy: 0.7743\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7032 - accuracy: 0.7621 - val_loss: 0.6899 - val_accuracy: 0.7743\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7001 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6759 - val_accuracy: 0.7743\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6765 - val_accuracy: 0.7743\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6761 - val_accuracy: 0.7743\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7621 - val_loss: 0.6762 - val_accuracy: 0.7743\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6769 - val_accuracy: 0.7743\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6777 - val_accuracy: 0.7743\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6764 - val_accuracy: 0.7743\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7009 - accuracy: 0.7621 - val_loss: 0.6760 - val_accuracy: 0.7743\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6778 - val_accuracy: 0.7743\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6760 - val_accuracy: 0.7743\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6767 - val_accuracy: 0.7743\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7621 - val_loss: 0.6767 - val_accuracy: 0.7743\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6772 - val_accuracy: 0.7743\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6770 - val_accuracy: 0.7743\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6771 - val_accuracy: 0.7743\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7621 - val_loss: 0.6759 - val_accuracy: 0.7743\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6760 - val_accuracy: 0.7743\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6772 - val_accuracy: 0.7743\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6777 - val_accuracy: 0.7743\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6774 - val_accuracy: 0.7743\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6993 - accuracy: 0.7621 - val_loss: 0.6764 - val_accuracy: 0.7743\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6761 - val_accuracy: 0.7743\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7621 - val_loss: 0.6760 - val_accuracy: 0.7743\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6760 - val_accuracy: 0.7743\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6763 - val_accuracy: 0.7743\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6763 - val_accuracy: 0.7743\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6766 - val_accuracy: 0.7743\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6767 - val_accuracy: 0.7743\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6772 - val_accuracy: 0.7743\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6994 - accuracy: 0.7621 - val_loss: 0.6764 - val_accuracy: 0.7743\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6767 - val_accuracy: 0.7743\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6763 - val_accuracy: 0.7743\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6995 - accuracy: 0.7621 - val_loss: 0.6770 - val_accuracy: 0.7743\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6993 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6994 - accuracy: 0.7621 - val_loss: 0.6765 - val_accuracy: 0.7743\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6759 - val_accuracy: 0.7743\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6993 - accuracy: 0.7621 - val_loss: 0.6768 - val_accuracy: 0.7743\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6759 - val_accuracy: 0.7743\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6765 - val_accuracy: 0.7743\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6774 - val_accuracy: 0.7743\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6762 - val_accuracy: 0.7743\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6773 - val_accuracy: 0.7743\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6773 - val_accuracy: 0.7743\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6767 - val_accuracy: 0.7743\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 4ms/step - loss: 0.6993 - accuracy: 0.7621 - val_loss: 0.6781 - val_accuracy: 0.7743\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7621 - val_loss: 0.6782 - val_accuracy: 0.7743\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6759 - val_accuracy: 0.7743\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6759 - val_accuracy: 0.7743\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7621 - val_loss: 0.6763 - val_accuracy: 0.7743\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6761 - val_accuracy: 0.7743\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6758 - val_accuracy: 0.7743\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7621 - val_loss: 0.6770 - val_accuracy: 0.7743\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7621 - val_loss: 0.6760 - val_accuracy: 0.7743\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6763 - val_accuracy: 0.7743\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7621 - val_loss: 0.6760 - val_accuracy: 0.7743\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6993 - accuracy: 0.7621 - val_loss: 0.6763 - val_accuracy: 0.7743\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7628 - val_loss: 0.6806 - val_accuracy: 0.7674\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7628 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7628 - val_loss: 0.6810 - val_accuracy: 0.7674\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.7628 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7628 - val_loss: 0.6803 - val_accuracy: 0.7674\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.7628 - val_loss: 0.6801 - val_accuracy: 0.7674\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7628 - val_loss: 0.6808 - val_accuracy: 0.7674\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.7628 - val_loss: 0.6791 - val_accuracy: 0.7674\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.7628 - val_loss: 0.6796 - val_accuracy: 0.7674\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7628 - val_loss: 0.6796 - val_accuracy: 0.7674\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7628 - val_loss: 0.6795 - val_accuracy: 0.7674\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7628 - val_loss: 0.6805 - val_accuracy: 0.7674\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7628 - val_loss: 0.6807 - val_accuracy: 0.7674\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7628 - val_loss: 0.6807 - val_accuracy: 0.7674\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7628 - val_loss: 0.6811 - val_accuracy: 0.7674\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7628 - val_loss: 0.6809 - val_accuracy: 0.7674\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7628 - val_loss: 0.6808 - val_accuracy: 0.7674\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7628 - val_loss: 0.6807 - val_accuracy: 0.7674\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7628 - val_loss: 0.6812 - val_accuracy: 0.7674\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.7628 - val_loss: 0.6795 - val_accuracy: 0.7674\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.8769 - accuracy: 0.7185 - val_loss: 0.6798 - val_accuracy: 0.7674\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.7004 - accuracy: 0.7627 - val_loss: 0.6802 - val_accuracy: 0.7674\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6805 - val_accuracy: 0.7674\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6808 - val_accuracy: 0.7674\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6803 - val_accuracy: 0.7674\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6798 - val_accuracy: 0.7674\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6801 - val_accuracy: 0.7674\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6803 - val_accuracy: 0.7674\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6811 - val_accuracy: 0.7674\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6809 - val_accuracy: 0.7674\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6799 - val_accuracy: 0.7674\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6802 - val_accuracy: 0.7674\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6798 - val_accuracy: 0.7674\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6801 - val_accuracy: 0.7674\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6801 - val_accuracy: 0.7674\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6798 - val_accuracy: 0.7674\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6802 - val_accuracy: 0.7674\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7627 - val_loss: 0.6804 - val_accuracy: 0.7674\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6799 - val_accuracy: 0.7674\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6810 - val_accuracy: 0.7674\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6797 - val_accuracy: 0.7674\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6805 - val_accuracy: 0.7674\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6802 - val_accuracy: 0.7674\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6806 - val_accuracy: 0.7674\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6803 - val_accuracy: 0.7674\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6804 - val_accuracy: 0.7674\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7627 - val_loss: 0.6813 - val_accuracy: 0.7674\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6801 - val_accuracy: 0.7674\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7627 - val_loss: 0.6813 - val_accuracy: 0.7674\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6805 - val_accuracy: 0.7674\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6803 - val_accuracy: 0.7674\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6798 - val_accuracy: 0.7674\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6797 - val_accuracy: 0.7674\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6799 - val_accuracy: 0.7674\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6807 - val_accuracy: 0.7674\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6807 - val_accuracy: 0.7674\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6799 - val_accuracy: 0.7674\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6801 - val_accuracy: 0.7674\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6798 - val_accuracy: 0.7674\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6805 - val_accuracy: 0.7674\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6804 - val_accuracy: 0.7674\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6804 - val_accuracy: 0.7674\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6801 - val_accuracy: 0.7674\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6812 - val_accuracy: 0.7674\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6796 - val_accuracy: 0.7674\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6797 - val_accuracy: 0.7674\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6805 - val_accuracy: 0.7674\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6813 - val_accuracy: 0.7674\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6807 - val_accuracy: 0.7674\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6993 - accuracy: 0.7627 - val_loss: 0.6796 - val_accuracy: 0.7674\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6807 - val_accuracy: 0.7674\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6809 - val_accuracy: 0.7674\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6806 - val_accuracy: 0.7674\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6812 - val_accuracy: 0.7674\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6806 - val_accuracy: 0.7674\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6799 - val_accuracy: 0.7674\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7627 - val_loss: 0.6804 - val_accuracy: 0.7674\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6993 - accuracy: 0.7627 - val_loss: 0.6811 - val_accuracy: 0.7674\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6806 - val_accuracy: 0.7674\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6811 - val_accuracy: 0.7674\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7627 - val_loss: 0.6821 - val_accuracy: 0.7674\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6806 - val_accuracy: 0.7674\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7627 - val_loss: 0.6811 - val_accuracy: 0.7674\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6804 - val_accuracy: 0.7674\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6802 - val_accuracy: 0.7674\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7627 - val_loss: 0.6798 - val_accuracy: 0.7674\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6809 - val_accuracy: 0.7674\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7674\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7627 - val_loss: 0.6806 - val_accuracy: 0.7674\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6992 - accuracy: 0.7627 - val_loss: 0.6797 - val_accuracy: 0.7674\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7627 - val_loss: 0.6805 - val_accuracy: 0.7674\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7627 - val_loss: 0.6802 - val_accuracy: 0.7674\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7494 - val_accuracy: 0.7332\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7499 - val_accuracy: 0.7332\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6909 - accuracy: 0.7665 - val_loss: 0.7534 - val_accuracy: 0.7332\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6915 - accuracy: 0.7665 - val_loss: 0.7498 - val_accuracy: 0.7332\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7507 - val_accuracy: 0.7332\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7516 - val_accuracy: 0.7332\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6914 - accuracy: 0.7665 - val_loss: 0.7504 - val_accuracy: 0.7332\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7543 - val_accuracy: 0.7332\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7506 - val_accuracy: 0.7332\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7481 - val_accuracy: 0.7332\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7509 - val_accuracy: 0.7332\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7495 - val_accuracy: 0.7332\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7486 - val_accuracy: 0.7332\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7492 - val_accuracy: 0.7332\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7519 - val_accuracy: 0.7332\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7504 - val_accuracy: 0.7332\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7512 - val_accuracy: 0.7332\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7523 - val_accuracy: 0.7332\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7530 - val_accuracy: 0.7332\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7483 - val_accuracy: 0.7332\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7510 - val_accuracy: 0.7332\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7500 - val_accuracy: 0.7332\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6915 - accuracy: 0.7665 - val_loss: 0.7511 - val_accuracy: 0.7332\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7500 - val_accuracy: 0.7332\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7504 - val_accuracy: 0.7332\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7511 - val_accuracy: 0.7332\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7537 - val_accuracy: 0.7332\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7514 - val_accuracy: 0.7332\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7496 - val_accuracy: 0.7332\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7509 - val_accuracy: 0.7332\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7507 - val_accuracy: 0.7332\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7514 - val_accuracy: 0.7332\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7484 - val_accuracy: 0.7332\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7483 - val_accuracy: 0.7332\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7527 - val_accuracy: 0.7332\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6915 - accuracy: 0.7665 - val_loss: 0.7491 - val_accuracy: 0.7332\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7498 - val_accuracy: 0.7332\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7485 - val_accuracy: 0.7332\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7495 - val_accuracy: 0.7332\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7497 - val_accuracy: 0.7332\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7491 - val_accuracy: 0.7332\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7497 - val_accuracy: 0.7332\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7495 - val_accuracy: 0.7332\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7498 - val_accuracy: 0.7332\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7495 - val_accuracy: 0.7332\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7521 - val_accuracy: 0.7332\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7479 - val_accuracy: 0.7332\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7526 - val_accuracy: 0.7332\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7517 - val_accuracy: 0.7332\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7488 - val_accuracy: 0.7332\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7491 - val_accuracy: 0.7332\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7487 - val_accuracy: 0.7332\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7516 - val_accuracy: 0.7332\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6909 - accuracy: 0.7665 - val_loss: 0.7478 - val_accuracy: 0.7332\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6917 - accuracy: 0.7665 - val_loss: 0.7485 - val_accuracy: 0.7332\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6909 - accuracy: 0.7665 - val_loss: 0.7481 - val_accuracy: 0.7332\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7497 - val_accuracy: 0.7332\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7497 - val_accuracy: 0.7332\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7506 - val_accuracy: 0.7332\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7504 - val_accuracy: 0.7332\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7524 - val_accuracy: 0.7332\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7489 - val_accuracy: 0.7332\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7480 - val_accuracy: 0.7332\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7488 - val_accuracy: 0.7332\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7482 - val_accuracy: 0.7332\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7485 - val_accuracy: 0.7332\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7487 - val_accuracy: 0.7332\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7517 - val_accuracy: 0.7332\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6909 - accuracy: 0.7665 - val_loss: 0.7479 - val_accuracy: 0.7332\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7506 - val_accuracy: 0.7332\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7483 - val_accuracy: 0.7332\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7493 - val_accuracy: 0.7332\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7506 - val_accuracy: 0.7332\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7497 - val_accuracy: 0.7332\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7497 - val_accuracy: 0.7332\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7506 - val_accuracy: 0.7332\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7503 - val_accuracy: 0.7332\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7489 - val_accuracy: 0.7332\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7488 - val_accuracy: 0.7332\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7509 - val_accuracy: 0.7332\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7490 - val_accuracy: 0.7332\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7525 - val_accuracy: 0.7332\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7499 - val_accuracy: 0.7332\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7491 - val_accuracy: 0.7332\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7503 - val_accuracy: 0.7332\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7485 - val_accuracy: 0.7332\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.7665 - val_loss: 0.7498 - val_accuracy: 0.7332\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7485 - val_accuracy: 0.7332\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7501 - val_accuracy: 0.7332\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7498 - val_accuracy: 0.7332\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7665 - val_loss: 0.7485 - val_accuracy: 0.7332\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7499 - val_accuracy: 0.7332\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7507 - val_accuracy: 0.7332\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7514 - val_accuracy: 0.7332\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7496 - val_accuracy: 0.7332\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7497 - val_accuracy: 0.7332\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7665 - val_loss: 0.7507 - val_accuracy: 0.7332\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7506 - val_accuracy: 0.7332\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7508 - val_accuracy: 0.7332\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.7665 - val_loss: 0.7496 - val_accuracy: 0.7332\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6856 - val_accuracy: 0.7674\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6863 - val_accuracy: 0.7674\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6863 - val_accuracy: 0.7674\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6862 - val_accuracy: 0.7674\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6862 - val_accuracy: 0.7674\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7627 - val_loss: 0.6864 - val_accuracy: 0.7674\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6868 - val_accuracy: 0.7674\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6868 - val_accuracy: 0.7674\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6979 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6862 - val_accuracy: 0.7674\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6980 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6864 - val_accuracy: 0.7674\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6862 - val_accuracy: 0.7674\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6980 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6864 - val_accuracy: 0.7674\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6863 - val_accuracy: 0.7674\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6980 - accuracy: 0.7627 - val_loss: 0.6864 - val_accuracy: 0.7674\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6863 - val_accuracy: 0.7674\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.7627 - val_loss: 0.6865 - val_accuracy: 0.7674\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6980 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6856 - val_accuracy: 0.7674\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6980 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6856 - val_accuracy: 0.7674\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6864 - val_accuracy: 0.7674\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6862 - val_accuracy: 0.7674\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6863 - val_accuracy: 0.7674\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6860 - val_accuracy: 0.7674\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6861 - val_accuracy: 0.7674\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7627 - val_loss: 0.6857 - val_accuracy: 0.7674\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6856 - val_accuracy: 0.7674\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.7627 - val_loss: 0.6858 - val_accuracy: 0.7674\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 0.6859 - val_accuracy: 0.7674\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6950 - accuracy: 0.7638 - val_loss: 0.7128 - val_accuracy: 0.7575\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7134 - val_accuracy: 0.7575\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7133 - val_accuracy: 0.7575\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7138 - val_accuracy: 0.7575\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7131 - val_accuracy: 0.7575\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7123 - val_accuracy: 0.7575\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7130 - val_accuracy: 0.7575\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7123 - val_accuracy: 0.7575\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7130 - val_accuracy: 0.7575\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6950 - accuracy: 0.7638 - val_loss: 0.7134 - val_accuracy: 0.7575\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6955 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7123 - val_accuracy: 0.7575\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7131 - val_accuracy: 0.7575\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7142 - val_accuracy: 0.7575\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6955 - accuracy: 0.7638 - val_loss: 0.7131 - val_accuracy: 0.7575\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6955 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7128 - val_accuracy: 0.7575\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6950 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7123 - val_accuracy: 0.7575\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7135 - val_accuracy: 0.7575\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7132 - val_accuracy: 0.7575\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6950 - accuracy: 0.7638 - val_loss: 0.7131 - val_accuracy: 0.7575\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7121 - val_accuracy: 0.7575\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7128 - val_accuracy: 0.7575\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7134 - val_accuracy: 0.7575\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7121 - val_accuracy: 0.7575\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7130 - val_accuracy: 0.7575\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7123 - val_accuracy: 0.7575\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7128 - val_accuracy: 0.7575\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7122 - val_accuracy: 0.7575\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7123 - val_accuracy: 0.7575\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6950 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7123 - val_accuracy: 0.7575\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7133 - val_accuracy: 0.7575\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7128 - val_accuracy: 0.7575\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7121 - val_accuracy: 0.7575\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7128 - val_accuracy: 0.7575\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7126 - val_accuracy: 0.7575\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7128 - val_accuracy: 0.7575\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7132 - val_accuracy: 0.7575\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7125 - val_accuracy: 0.7575\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7122 - val_accuracy: 0.7575\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7122 - val_accuracy: 0.7575\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.7638 - val_loss: 0.7124 - val_accuracy: 0.7575\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6951 - accuracy: 0.7638 - val_loss: 0.7137 - val_accuracy: 0.7575\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.7638 - val_loss: 0.7129 - val_accuracy: 0.7575\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6949 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.7575\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6955 - accuracy: 0.7638 - val_loss: 0.7123 - val_accuracy: 0.7575\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7638 - val_loss: 0.7122 - val_accuracy: 0.7575\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6733 - val_accuracy: 0.7753\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6734 - val_accuracy: 0.7753\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6731 - val_accuracy: 0.7753\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6726 - val_accuracy: 0.7753\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6732 - val_accuracy: 0.7753\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6729 - val_accuracy: 0.7753\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6731 - val_accuracy: 0.7753\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6722 - val_accuracy: 0.7753\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6722 - val_accuracy: 0.7753\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6726 - val_accuracy: 0.7753\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6730 - val_accuracy: 0.7753\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6728 - val_accuracy: 0.7753\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6726 - val_accuracy: 0.7753\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6731 - val_accuracy: 0.7753\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6730 - val_accuracy: 0.7753\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6735 - val_accuracy: 0.7753\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6994 - accuracy: 0.7618 - val_loss: 0.6721 - val_accuracy: 0.7753\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6729 - val_accuracy: 0.7753\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6729 - val_accuracy: 0.7753\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6731 - val_accuracy: 0.7753\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6723 - val_accuracy: 0.7753\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6721 - val_accuracy: 0.7753\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6731 - val_accuracy: 0.7753\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6726 - val_accuracy: 0.7753\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6723 - val_accuracy: 0.7753\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6731 - val_accuracy: 0.7753\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6734 - val_accuracy: 0.7753\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6736 - val_accuracy: 0.7753\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6726 - val_accuracy: 0.7753\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6732 - val_accuracy: 0.7753\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6737 - val_accuracy: 0.7753\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6726 - val_accuracy: 0.7753\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6732 - val_accuracy: 0.7753\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6733 - val_accuracy: 0.7753\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6994 - accuracy: 0.7618 - val_loss: 0.6721 - val_accuracy: 0.7753\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6728 - val_accuracy: 0.7753\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6735 - val_accuracy: 0.7753\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6732 - val_accuracy: 0.7753\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6729 - val_accuracy: 0.7753\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6730 - val_accuracy: 0.7753\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6735 - val_accuracy: 0.7753\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6723 - val_accuracy: 0.7753\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6731 - val_accuracy: 0.7753\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6730 - val_accuracy: 0.7753\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6740 - val_accuracy: 0.7753\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6730 - val_accuracy: 0.7753\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6722 - val_accuracy: 0.7753\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6721 - val_accuracy: 0.7753\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6730 - val_accuracy: 0.7753\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6722 - val_accuracy: 0.7753\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6729 - val_accuracy: 0.7753\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6731 - val_accuracy: 0.7753\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6994 - accuracy: 0.7618 - val_loss: 0.6723 - val_accuracy: 0.7753\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6735 - val_accuracy: 0.7753\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6722 - val_accuracy: 0.7753\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6732 - val_accuracy: 0.7753\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6722 - val_accuracy: 0.7753\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6729 - val_accuracy: 0.7753\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6728 - val_accuracy: 0.7753\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6729 - val_accuracy: 0.7753\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6722 - val_accuracy: 0.7753\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6736 - val_accuracy: 0.7753\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6728 - val_accuracy: 0.7753\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6721 - val_accuracy: 0.7753\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6727 - val_accuracy: 0.7753\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6725 - val_accuracy: 0.7753\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6726 - val_accuracy: 0.7753\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 2s 8ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6726 - val_accuracy: 0.7753\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7618 - val_loss: 0.6723 - val_accuracy: 0.7753\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7618 - val_loss: 0.6724 - val_accuracy: 0.7753\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 5ms/step - loss: 0.6997 - accuracy: 0.7618 - val_loss: 0.6728 - val_accuracy: 0.7753\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7618 - val_loss: 0.6730 - val_accuracy: 0.7753\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6910 - val_accuracy: 0.7671\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6907 - val_accuracy: 0.7671\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6908 - val_accuracy: 0.7671\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6907 - val_accuracy: 0.7671\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6909 - val_accuracy: 0.7671\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6912 - val_accuracy: 0.7671\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6907 - val_accuracy: 0.7671\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6913 - val_accuracy: 0.7671\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6907 - val_accuracy: 0.7671\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6907 - val_accuracy: 0.7671\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6979 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6908 - val_accuracy: 0.7671\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6907 - val_accuracy: 0.7671\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6906 - val_accuracy: 0.7671\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.7627 - val_loss: 0.6910 - val_accuracy: 0.7671\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6907 - val_accuracy: 0.7671\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6908 - val_accuracy: 0.7671\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6903 - val_accuracy: 0.7671\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7627 - val_loss: 0.6904 - val_accuracy: 0.7671\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7627 - val_loss: 0.6905 - val_accuracy: 0.7671\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6718 - val_accuracy: 0.7836\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.6718 - val_accuracy: 0.7836\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6719 - val_accuracy: 0.7836\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6711 - val_accuracy: 0.7836\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6716 - val_accuracy: 0.7836\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6716 - val_accuracy: 0.7836\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6723 - val_accuracy: 0.7836\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6710 - val_accuracy: 0.7836\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6713 - val_accuracy: 0.7836\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6721 - val_accuracy: 0.7836\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6719 - val_accuracy: 0.7836\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6719 - val_accuracy: 0.7836\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6722 - val_accuracy: 0.7836\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6709 - val_accuracy: 0.7836\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7609 - val_loss: 0.6727 - val_accuracy: 0.7836\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.6720 - val_accuracy: 0.7836\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6710 - val_accuracy: 0.7836\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6724 - val_accuracy: 0.7836\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6709 - val_accuracy: 0.7836\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6711 - val_accuracy: 0.7836\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6709 - val_accuracy: 0.7836\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.7000 - accuracy: 0.7609 - val_loss: 0.6711 - val_accuracy: 0.7836\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6722 - val_accuracy: 0.7836\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6718 - val_accuracy: 0.7836\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6720 - val_accuracy: 0.7836\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6712 - val_accuracy: 0.7836\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6711 - val_accuracy: 0.7836\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7609 - val_loss: 0.6705 - val_accuracy: 0.7836\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6715 - val_accuracy: 0.7836\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6719 - val_accuracy: 0.7836\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6716 - val_accuracy: 0.7836\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6721 - val_accuracy: 0.7836\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6731 - val_accuracy: 0.7836\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6721 - val_accuracy: 0.7836\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6718 - val_accuracy: 0.7836\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6724 - val_accuracy: 0.7836\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6712 - val_accuracy: 0.7836\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6713 - val_accuracy: 0.7836\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.6715 - val_accuracy: 0.7836\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.7000 - accuracy: 0.7609 - val_loss: 0.6711 - val_accuracy: 0.7836\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6705 - val_accuracy: 0.7836\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6712 - val_accuracy: 0.7836\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6715 - val_accuracy: 0.7836\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6716 - val_accuracy: 0.7836\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6724 - val_accuracy: 0.7836\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7609 - val_loss: 0.6706 - val_accuracy: 0.7836\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.6715 - val_accuracy: 0.7836\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6718 - val_accuracy: 0.7836\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6708 - val_accuracy: 0.7836\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6721 - val_accuracy: 0.7836\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6713 - val_accuracy: 0.7836\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6716 - val_accuracy: 0.7836\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6712 - val_accuracy: 0.7836\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6715 - val_accuracy: 0.7836\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6715 - val_accuracy: 0.7836\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6725 - val_accuracy: 0.7836\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6719 - val_accuracy: 0.7836\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.7001 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6711 - val_accuracy: 0.7836\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6711 - val_accuracy: 0.7836\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6712 - val_accuracy: 0.7836\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6712 - val_accuracy: 0.7836\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6713 - val_accuracy: 0.7836\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6706 - val_accuracy: 0.7836\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6709 - val_accuracy: 0.7836\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6712 - val_accuracy: 0.7836\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6996 - accuracy: 0.7609 - val_loss: 0.6729 - val_accuracy: 0.7836\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6716 - val_accuracy: 0.7836\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6716 - val_accuracy: 0.7836\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6726 - val_accuracy: 0.7836\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6715 - val_accuracy: 0.7836\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6713 - val_accuracy: 0.7836\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6714 - val_accuracy: 0.7836\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6997 - accuracy: 0.7609 - val_loss: 0.6709 - val_accuracy: 0.7836\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7609 - val_loss: 0.6717 - val_accuracy: 0.7836\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6711 - val_accuracy: 0.7836\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7609 - val_loss: 0.6712 - val_accuracy: 0.7836\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7326 - val_accuracy: 0.7411\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7335 - val_accuracy: 0.7411\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7317 - val_accuracy: 0.7411\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7333 - val_accuracy: 0.7411\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7316 - val_accuracy: 0.7411\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7316 - val_accuracy: 0.7411\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7322 - val_accuracy: 0.7411\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7327 - val_accuracy: 0.7411\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7330 - val_accuracy: 0.7411\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7332 - val_accuracy: 0.7411\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7325 - val_accuracy: 0.7411\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7327 - val_accuracy: 0.7411\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7332 - val_accuracy: 0.7411\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7324 - val_accuracy: 0.7411\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7320 - val_accuracy: 0.7411\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7332 - val_accuracy: 0.7411\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7326 - val_accuracy: 0.7411\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7332 - val_accuracy: 0.7411\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7335 - val_accuracy: 0.7411\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.7656 - val_loss: 0.7325 - val_accuracy: 0.7411\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7324 - val_accuracy: 0.7411\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6928 - accuracy: 0.7656 - val_loss: 0.7318 - val_accuracy: 0.7411\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7319 - val_accuracy: 0.7411\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7330 - val_accuracy: 0.7411\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7331 - val_accuracy: 0.7411\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7328 - val_accuracy: 0.7411\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7327 - val_accuracy: 0.7411\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7329 - val_accuracy: 0.7411\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7330 - val_accuracy: 0.7411\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7330 - val_accuracy: 0.7411\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7331 - val_accuracy: 0.7411\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7320 - val_accuracy: 0.7411\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7339 - val_accuracy: 0.7411\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7319 - val_accuracy: 0.7411\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.7656 - val_loss: 0.7319 - val_accuracy: 0.7411\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7326 - val_accuracy: 0.7411\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7319 - val_accuracy: 0.7411\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7332 - val_accuracy: 0.7411\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7317 - val_accuracy: 0.7411\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7322 - val_accuracy: 0.7411\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7330 - val_accuracy: 0.7411\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7330 - val_accuracy: 0.7411\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7324 - val_accuracy: 0.7411\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7317 - val_accuracy: 0.7411\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7329 - val_accuracy: 0.7411\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7315 - val_accuracy: 0.7411\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7335 - val_accuracy: 0.7411\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7329 - val_accuracy: 0.7411\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7329 - val_accuracy: 0.7411\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7323 - val_accuracy: 0.7411\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7325 - val_accuracy: 0.7411\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7332 - val_accuracy: 0.7411\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7320 - val_accuracy: 0.7411\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7330 - val_accuracy: 0.7411\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7322 - val_accuracy: 0.7411\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7324 - val_accuracy: 0.7411\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7325 - val_accuracy: 0.7411\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7319 - val_accuracy: 0.7411\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7339 - val_accuracy: 0.7411\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7342 - val_accuracy: 0.7411\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7317 - val_accuracy: 0.7411\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7316 - val_accuracy: 0.7411\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7323 - val_accuracy: 0.7411\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7324 - val_accuracy: 0.7411\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7331 - val_accuracy: 0.7411\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7326 - val_accuracy: 0.7411\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7322 - val_accuracy: 0.7411\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7335 - val_accuracy: 0.7411\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7319 - val_accuracy: 0.7411\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7328 - val_accuracy: 0.7411\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.7656 - val_loss: 0.7320 - val_accuracy: 0.7411\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7326 - val_accuracy: 0.7411\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6931 - accuracy: 0.7656 - val_loss: 0.7322 - val_accuracy: 0.7411\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7324 - val_accuracy: 0.7411\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7330 - val_accuracy: 0.7411\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6928 - accuracy: 0.7656 - val_loss: 0.7319 - val_accuracy: 0.7411\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7328 - val_accuracy: 0.7411\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7316 - val_accuracy: 0.7411\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7315 - val_accuracy: 0.7411\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7325 - val_accuracy: 0.7411\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7321 - val_accuracy: 0.7411\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7326 - val_accuracy: 0.7411\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7324 - val_accuracy: 0.7411\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7324 - val_accuracy: 0.7411\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7320 - val_accuracy: 0.7411\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7331 - val_accuracy: 0.7411\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.7656 - val_loss: 0.7323 - val_accuracy: 0.7411\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7315 - val_accuracy: 0.7411\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7326 - val_accuracy: 0.7411\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7656 - val_loss: 0.7326 - val_accuracy: 0.7411\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7656 - val_loss: 0.7320 - val_accuracy: 0.7411\n",
            "Epoch 1/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 2/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 3/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 4/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 5/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 6/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 7/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 8/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 9/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 10/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 11/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 12/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 13/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 14/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 15/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6979 - val_accuracy: 0.7644\n",
            "Epoch 16/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 17/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6979 - val_accuracy: 0.7644\n",
            "Epoch 18/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 19/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6970 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 20/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6979 - val_accuracy: 0.7644\n",
            "Epoch 21/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6979 - val_accuracy: 0.7644\n",
            "Epoch 22/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 23/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 24/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 25/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 26/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 27/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 28/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 29/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 30/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 31/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6970 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 32/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 33/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 34/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 35/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 36/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 37/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 38/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 39/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 40/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6976 - val_accuracy: 0.7644\n",
            "Epoch 41/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 42/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 43/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 44/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6966 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 45/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 46/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 47/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 48/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6980 - val_accuracy: 0.7644\n",
            "Epoch 49/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6976 - val_accuracy: 0.7644\n",
            "Epoch 50/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 51/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 52/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 53/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 54/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 55/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 56/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 57/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 58/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6966 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 59/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 60/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 61/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 62/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 63/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 64/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 65/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 66/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 67/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 68/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 69/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 70/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 71/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 72/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 73/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 74/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 75/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6976 - val_accuracy: 0.7644\n",
            "Epoch 76/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 77/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 78/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 79/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 80/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6979 - val_accuracy: 0.7644\n",
            "Epoch 81/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 82/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 83/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 84/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6979 - val_accuracy: 0.7644\n",
            "Epoch 85/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 86/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6966 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 87/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 88/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 89/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 90/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 91/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 92/100\n",
            "206/206 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 93/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 94/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 95/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 96/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 97/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6969 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 98/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6978 - val_accuracy: 0.7644\n",
            "Epoch 99/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6968 - accuracy: 0.7630 - val_loss: 0.6977 - val_accuracy: 0.7644\n",
            "Epoch 100/100\n",
            "206/206 [==============================] - 1s 7ms/step - loss: 0.6967 - accuracy: 0.7630 - val_loss: 0.6979 - val_accuracy: 0.7644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F4WuQw_vqR7"
      },
      "source": [
        "Clearly K-fold cross validation impoved the results by 3% which can be imporoved even more by data cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qguEgwwqsUwP"
      },
      "source": [
        "X_test=[]\n",
        "y_test=[]\n",
        "segment_size=8\n",
        "for i in range(int(len(covDataset)*2/3),int(len(covDataset))):\n",
        "  print(i)\n",
        "  if (covDataset.iloc[i,0]+'.webm') in files:\n",
        "    arr,sr=lb.load(f'./public_dataset/{covDataset.iloc[i,0]+\".webm\"}',sr=48000)\n",
        "  if (covDataset.iloc[i,0]+'.ogg') in files:\n",
        "    arr,sr=lb.load(f'./public_dataset/{covDataset.iloc[i,0]+\".ogg\"}',sr=48000)\n",
        "  duration=lb.get_duration(arr,sr=48000)\n",
        "  itime=0\n",
        "  ftime=0\n",
        "  for j in range(int(duration/segment_size)):\n",
        "    itime=j*segment_size\n",
        "    ftime=itime+segment_size\n",
        "    feautures=lb.feature.mfcc(y=arr[itime:ftime], sr=sr, n_mfcc=10)\n",
        "    X_test.append(feautures)\n",
        "    y_test.append(covDataset.iloc[i,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g3KoYj-xQPq"
      },
      "source": [
        "X_test=np.array(X_test)\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1])\n",
        "Le_test=preprocessing.LabelEncoder()\n",
        "ytest=Le_test.fit_transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiPktSaqzCah"
      },
      "source": [
        "preds=Kmodel.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atLMKqMszH0r",
        "outputId": "08f4f8a2-6947-4738-927d-6d52f8a9962d"
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3708, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH6FFhiWzJ6L"
      },
      "source": [
        "preds=[pred.argmax() for pred in preds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNZ0LvKzT6w"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3TU95aHzioF",
        "outputId": "7f156fa2-5c45-4cba-9b7d-32465dfcb073"
      },
      "source": [
        "print(classification_report(ytest, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       273\n",
            "           1       0.77      1.00      0.87      2854\n",
            "           2       0.00      0.00      0.00       581\n",
            "\n",
            "    accuracy                           0.77      3708\n",
            "   macro avg       0.26      0.33      0.29      3708\n",
            "weighted avg       0.59      0.77      0.67      3708\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EsiOPuAN2Pp"
      },
      "source": [
        "###From the classification score it is clear that the model is able to find the model can find healthy people more easily and is also presenting some Covid19 results as positive also this may be attributed to the fact that the given dataset has many more healthy results as compared to covid19 or symptomatic almost 10:1 which is not healthy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLSFQS0r0R4I",
        "outputId": "eeeac543-471e-4176-91d1-68edebf6dd84"
      },
      "source": [
        "Le_test.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['COVID-19', 'healthy', 'symptomatic'], dtype='<U11')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWqPNBWHOCs5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}